"""
Intrinsic evaluation for *uncertain* event data.

This script mirrors the structure of:
  `evaluation/evaluation_of_activity_distances/intrinsic_evaluation/evaluation_activity_distance_intrinsic.py`

Key differences
---------------
- Input logs are read from `uncertain_event_logs/` and parsed with `read_uncertain_xes`.
- We first cap each event distribution to top-5 labels (including NA) and renormalize.
- Ground truth logs are generated by applying the same activity replacement idea to uncertain traces:
  probability mass of replaced activities is redirected to trace-consistent replacement labels.
- We evaluate methods across 5 uncertainty levels k=1..5 (top-k truncation + renormalization).
- Methods evaluated are the uncertain window-based count methods and uncertain act2vec.

Outputs
-------
1) Ground truth logs (cached):
   evaluation/evaluation_of_activity_distances/intrinsic_evaluation_uncertain/newly_created_logs/<log_name>/
     r_<r>_w_<w>_s_<sampling_size>.pkl
   Each file stores: dict[activities_to_replace_tuple] -> UncertainEventLog (base top-5).

2) Per-method per-setting cached results:
   evaluation/evaluation_of_activity_distances/intrinsic_evaluation_uncertain/results/<log_name>/<method>/
     r_<r>_w_<w>_s_<sampling_size>_u_<k>.pkl

3) Aggregated CSV outputs (mirrors deterministic naming, adds u):
   results/activity_distances/intrinsic_uncertain/<log_name>/
     <log_name>_distfunc_<method>_u<u>_r<r>_w<w>_samplesize_<sampling_size>.csv
"""

from __future__ import annotations

import multiprocessing
import os
import pickle
import time
from multiprocessing import Pool

# Ensure repo root is importable when running this file directly by path (IDE / python -u ...)
import sys
from pathlib import Path
REPO_ROOT = Path(__file__).resolve().parents[3]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

from definitions import ROOT_DIR
from evaluation.data_util.uncertain_evaluation_helpers import add_window_size_evaluation
from evaluation.data_util.util_activity_distances_intrinsic_metrics_light import (
    get_activities_to_replace,
    get_knn_dict,
    get_precision_at_k,
    get_triplet,
    get_diameter,
)
from evaluation.data_util.util_activity_distances_intrinsic_uncertain import (
    apply_uncertainty_level,
    load_uncertain_ground_truth_logs,
    save_uncertain_ground_truth_logs,
    load_uncertain_result,
    save_uncertain_result,
    uncertainty_stats,
    activities_in_uncertain_log,
    topk_distribution,
    get_uncertain_logs_with_replaced_activities_dict,
)
from evaluation.data_util.util_activity_distances_uncertain_intrinsic import get_uncertain_activity_distance_matrix_dict
from uncertain_utils.uncertain_xes_reader import read_uncertain_xes, UncertainEventLog


UNCERTAINTY_LEVELS = [1, 2, 3, 4, 5]
BASE_TOPK = 5

# Debug / progress verbosity
VERBOSE = True
VERBOSE_MAX_EXAMPLES = 3  # limit per-section example prints


def _safe_progress(msg: str) -> None:
    try:
        print(msg, flush=True)
    except BrokenPipeError:
        pass


def _v(msg: str) -> None:
    if VERBOSE:
        _safe_progress(msg)


def _read_uncertain_log_from_folder(log_name: str) -> UncertainEventLog:
    """
    Reads `<ROOT_DIR>/uncertain_event_logs/<log_name>.xes` (or .xes.gz if present).
    For convenience (and to not force repo restructuring), we fall back to `<ROOT_DIR>/<log_name>.xes`
    if no file is found in `uncertain_event_logs/`.
    """
    xes = os.path.join(ROOT_DIR, "uncertain_event_logs", f"{log_name}.xes")
    xes_gz = os.path.join(ROOT_DIR, "uncertain_event_logs", f"{log_name}.xes.gz")
    if os.path.exists(xes_gz):
        path = xes_gz
    elif os.path.exists(xes):
        path = xes
    else:
        # fallback to repo root
        root_xes = os.path.join(ROOT_DIR, f"{log_name}.xes")
        root_xes_gz = os.path.join(ROOT_DIR, f"{log_name}.xes.gz")
        if os.path.exists(root_xes_gz):
            path = root_xes_gz
        elif os.path.exists(root_xes):
            path = root_xes
        else:
            raise FileNotFoundError(
                f"Uncertain event log not found. Tried: {xes_gz}, {xes}, {root_xes_gz}, {root_xes}"
            )
    _v(f"[uncertain-intrinsic] using XES file: {path}")
    return read_uncertain_xes(path)


def _cap_log_top5(log: UncertainEventLog, *, na_label: str = "NA") -> UncertainEventLog:
    return apply_uncertainty_level(log, k=BASE_TOPK, na_label=na_label)


def evaluate_intrinsic_uncertain(
    activity_distance_functions,
    log_list,
    r_min,
    w,
    sampling_size,
    load_ground_truth_logs: bool,
    na_label: str = "NA",
):
    for log_name in log_list:
        _safe_progress(f"[uncertain-intrinsic] loading log: {log_name}")
        log_u = _read_uncertain_log_from_folder(log_name)

        # Cap to base top-5 (including NA if present), then renormalize.
        log_u5 = _cap_log_top5(log_u, na_label=na_label)
        stats5 = uncertainty_stats(log_u5, na_label=na_label)
        _safe_progress(f"[uncertain-intrinsic] base top-5 stats: {stats5}")
        _v(f"[uncertain-intrinsic] uncertainty levels u={UNCERTAINTY_LEVELS} (top-u per event, renorm)")

        # Choose replaceable activities (exclude NA)
        alphabet = activities_in_uncertain_log(log_u5, exclude={na_label})
        r = min(r_min, len(alphabet))
        _v(f"[uncertain-intrinsic] |A| (excluding NA) = {len(alphabet)} ; r_min={r_min} -> r_max={r}")

        # Subproblems (same structure as deterministic evaluation)
        combinations = [
            (
                different_activities_to_replace_count,
                activities_to_replace_with_count,
                log_name,
                log_u5,
                alphabet,
                activity_distance_functions,
                sampling_size,
                load_ground_truth_logs,
                na_label,
            )
            for different_activities_to_replace_count in range(1, r + 1)
            for activities_to_replace_with_count in range(2, w + 1)
        ]

        # Match deterministic core usage pattern
        total_cores = multiprocessing.cpu_count()
        cores_to_use = max(1, int(total_cores * 0.8))
        _v(f"[uncertain-intrinsic] subproblems={len(combinations)} cores_to_use={cores_to_use} mp={0}")
        mp = 0
        if mp == 1:
            with Pool(processes=cores_to_use) as pool:
                results = pool.map(intrinsic_evaluation_uncertain, combinations)
        else:
            results = [intrinsic_evaluation_uncertain(c) for c in combinations]

        # Save aggregated results as CSVs (per method and per uncertainty level)
        save_intrinsic_results_uncertain(activity_distance_functions, results, log_name, r, w, sampling_size)


def intrinsic_evaluation_uncertain(args):
    (
        different_activities_to_replace_count,
        activities_to_replace_with_count,
        log_name,
        base_log_u5,
        alphabet,
        activity_distance_function_list,
        sampling_size,
        load_logs,
        na_label,
    ) = args

    # Ground truth log cache path mirrors deterministic naming.
    logs_with_replaced_activities_dict = None
    if load_logs:
        _v(
            f"[uncertain-intrinsic] GT load attempt: log={log_name} r={different_activities_to_replace_count} "
            f"w={activities_to_replace_with_count} s={sampling_size}"
        )
        logs_with_replaced_activities_dict = load_uncertain_ground_truth_logs(
            log_name,
            different_activities_to_replace_count=different_activities_to_replace_count,
            activities_to_replace_with_count=activities_to_replace_with_count,
            sampling_size=sampling_size,
        )
        if logs_with_replaced_activities_dict is not None:
            _v(f"[uncertain-intrinsic] GT cache hit: runs={len(logs_with_replaced_activities_dict)}")

    if logs_with_replaced_activities_dict is None:
        activities_to_replace_in_each_run_list = get_activities_to_replace(
            alphabet, different_activities_to_replace_count, sampling_size
        )
        _v(
            f"[uncertain-intrinsic] GT generating: runs={len(activities_to_replace_in_each_run_list)} "
            f"(showing up to {VERBOSE_MAX_EXAMPLES}): {activities_to_replace_in_each_run_list[:VERBOSE_MAX_EXAMPLES]}"
        )
        logs_with_replaced_activities_dict = get_uncertain_logs_with_replaced_activities_dict(
            activities_to_replace_in_each_run_list,
            base_log_u5,
            different_activities_to_replace_count=different_activities_to_replace_count,
            activities_to_replace_with_count=activities_to_replace_with_count,
            na_label=na_label,
        )
        gt_path = save_uncertain_ground_truth_logs(
            log_name,
            different_activities_to_replace_count=different_activities_to_replace_count,
            activities_to_replace_with_count=activities_to_replace_with_count,
            sampling_size=sampling_size,
            logs_with_replaced_activities_dict=logs_with_replaced_activities_dict,
        )
        _v(f"[uncertain-intrinsic] GT saved: {gt_path}")
    else:
        activities_to_replace_in_each_run_list = [key for key in logs_with_replaced_activities_dict.keys()]
        _v(
            f"[uncertain-intrinsic] GT loaded: runs={len(activities_to_replace_in_each_run_list)} "
            f"(showing up to {VERBOSE_MAX_EXAMPLES}): {activities_to_replace_in_each_run_list[:VERBOSE_MAX_EXAMPLES]}"
        )

    _safe_progress(
        f"[uncertain-intrinsic] start r={different_activities_to_replace_count} w={activities_to_replace_with_count}"
    )

    # Results are returned as a list (one entry per method in activity_distance_function_list),
    # matching deterministic script structure. Each entry itself is a list over uncertainty levels.
    results_per_method = []

    for activity_distance_function in activity_distance_function_list:
        method_results_by_u = []
        _v(f"[uncertain-intrinsic] method: {activity_distance_function}")

        for u in UNCERTAINTY_LEVELS:
            # Cache check
            cached = None
            if load_logs:
                cached = load_uncertain_result(
                    log_name=log_name,
                    activity_distance_function=activity_distance_function,
                    different_activities_to_replace_count=different_activities_to_replace_count,
                    activities_to_replace_with_count=activities_to_replace_with_count,
                    sampling_size=sampling_size,
                    uncertainty_level=u,
                )
            if cached is not None:
                _v(
                    f"[uncertain-intrinsic] cache hit: method={activity_distance_function} "
                    f"r={different_activities_to_replace_count} w={activities_to_replace_with_count} u={u}"
                )
                method_results_by_u.append(cached)
                continue

            # Evaluate this method at uncertainty level u
            diameter_list = []
            precision_at_w_minus_1_list = []
            precision_at_1_list = []
            triplet_list = []
            entropy_list = []
            t_u0 = time.time()
            _v(f"[uncertain-intrinsic] evaluating u={u} for method={activity_distance_function} ...")

            for activities_to_replace in activities_to_replace_in_each_run_list:
                # take the base top-5 ground truth log and derive level-u by truncation
                gt_u5 = logs_with_replaced_activities_dict[activities_to_replace]
                gt_u = apply_uncertainty_level(gt_u5, k=u, na_label=na_label)
                stats_u = uncertainty_stats(gt_u, na_label=na_label)
                entropy_list.append(stats_u["avg_norm_entropy"])

                # Alphabet for intrinsic metrics (exclude NA)
                alphabet_u = activities_in_uncertain_log(gt_u, exclude={na_label})

                logs_for_run = {activities_to_replace: gt_u}

                # Compute distances between activities for this method and this ground truth log
                t_dist0 = time.time()
                activity_distance_matrix_dict = get_uncertain_activity_distance_matrix_dict(
                    [activity_distance_function],
                    logs_for_run,
                    na_label=na_label,
                    progress=_safe_progress if VERBOSE and "act2vec" in activity_distance_function else None,
                )
                t_dist = time.time() - t_dist0
                if VERBOSE:
                    _v(
                        f"[uncertain-intrinsic] u={u} run activities_to_replace={activities_to_replace} "
                        f"stats={stats_u} |A_u|={len(alphabet_u)} dist_time={t_dist:.2f}s"
                    )

                reverse = False  # smaller distance = more similar (cosine distance)

                diameter_list.append(
                    get_diameter(
                        activity_distance_matrix_dict,
                        activities_to_replace_with_count,
                        reverse,
                        alphabet_u,
                    )
                )

                w_minus_one_nn_dict = get_knn_dict(
                    activity_distance_matrix_dict, activities_to_replace_with_count, reverse, activities_to_replace_with_count - 1
                )
                precision_at_w_minus_1_dict = get_precision_at_k(w_minus_one_nn_dict, [activity_distance_function])
                precision_at_w_minus_1_list.append(precision_at_w_minus_1_dict[activity_distance_function])

                one_nn_dict = get_knn_dict(activity_distance_matrix_dict, activities_to_replace_with_count, reverse, 1)
                precision_at_1_dict = get_precision_at_k(one_nn_dict, [activity_distance_function])
                precision_at_1_list.append(precision_at_1_dict[activity_distance_function])

                triplet_list.append(
                    get_triplet(
                        activity_distance_matrix_dict,
                        activities_to_replace_with_count,
                        reverse,
                        alphabet_u,
                    )
                )

            # Aggregate over runs
            diameter = sum(diameter_list) / len(diameter_list)
            precision_at_w_minus_1 = sum(precision_at_w_minus_1_list) / len(precision_at_w_minus_1_list)
            precision_at_1 = sum(precision_at_1_list) / len(precision_at_1_list)
            triplet = sum(triplet_list) / len(triplet_list)
            avg_entropy = sum(entropy_list) / len(entropy_list)

            results = (
                different_activities_to_replace_count,
                activities_to_replace_with_count,
                u,
                avg_entropy,
                diameter,
                precision_at_w_minus_1,
                precision_at_1,
                triplet,
            )
            res_path = save_uncertain_result(
                results,
                log_name=log_name,
                activity_distance_function=activity_distance_function,
                different_activities_to_replace_count=different_activities_to_replace_count,
                activities_to_replace_with_count=activities_to_replace_with_count,
                sampling_size=sampling_size,
                uncertainty_level=u,
            )
            _v(
                f"[uncertain-intrinsic] saved result: u={u} method={activity_distance_function} "
                f"avg_entropy={avg_entropy:.3f} diameter={diameter:.3f} prec@w-1={precision_at_w_minus_1:.3f} "
                f"prec@1={precision_at_1:.3f} triplet={triplet:.3f} time_u={time.time()-t_u0:.2f}s -> {res_path}"
            )
            method_results_by_u.append(results)

        results_per_method.append(method_results_by_u)

    _safe_progress(
        f"[uncertain-intrinsic] end r={different_activities_to_replace_count} w={activities_to_replace_with_count} s={sampling_size}"
    )
    return results_per_method


def save_intrinsic_results_uncertain(activity_distance_functions, results, log_name, r, w, sampling_size):
    """
    Save CSVs + dfavg pickles mirroring deterministic intrinsic output, but one set per uncertainty level u.
    """
    import pandas as pd
    from pathlib import Path
    import pickle

    # results is list over subproblems; each subproblem yields list over methods; each method yields list over u
    # We want, for each method and each u, a DataFrame with rows (r,w,u,entropy,metrics).
    for m_idx, method in enumerate(activity_distance_functions):
        # collect all entries for this method across subproblems
        all_entries = []
        for sub in results:
            # sub[m_idx] is list over uncertainty levels (tuples)
            all_entries.extend(sub[m_idx])

        # split by uncertainty level
        by_u = {}
        for entry in all_entries:
            _, _, u, *_rest = entry
            by_u.setdefault(u, []).append(entry)

        for u, entries in by_u.items():
            df = pd.DataFrame(
                entries,
                columns=["r", "w", "u", "avg_norm_entropy", "diameter", "precision@w-1", "precision@1", "triplet"],
            )
            out_dir = os.path.join(ROOT_DIR, "results", "activity_distances", "intrinsic_uncertain", log_name)
            Path(out_dir).mkdir(parents=True, exist_ok=True)
            csv = f"{log_name}_distfunc_{method}_u{u}_r{r}_w{w}_samplesize_{sampling_size}.csv"
            csv = csv.replace("/", "_").replace("\\", "_")
            df.to_csv(os.path.join(out_dir, csv), index=False)

            # Mirror deterministic "dfavg" output: average over all r/w in this run, per method and u.
            df_average_values = pd.DataFrame(
                [{
                    "Log Name": log_name,
                    "Distance Function": method,
                    "u": int(u),
                    "avg_norm_entropy": float(df["avg_norm_entropy"].mean()) if len(df) else 0.0,
                    "diameter": float(df["diameter"].mean()) if len(df) else 0.0,
                    "precision@w-1": float(df["precision@w-1"].mean()) if len(df) else 0.0,
                    "precision@1": float(df["precision@1"].mean()) if len(df) else 0.0,
                    "triplet": float(df["triplet"].mean()) if len(df) else 0.0,
                }]
            )
            df_avg_dir = os.path.join(
                ROOT_DIR, "results", "activity_distances", "intrinsic_uncertain_df_avg", log_name, f"u_{u}"
            )
            os.makedirs(df_avg_dir, exist_ok=True)
            file_name = f"dfavg_r{r}_w{w}_samplesize_{sampling_size}.pkl"
            file_path = os.path.join(df_avg_dir, file_name)
            with open(file_path, "wb") as f:
                pickle.dump(df_average_values, f)


if __name__ == "__main__":
    # ==============================================================================
    # Similarity Methods to Evaluate (uncertain)
    # ==============================================================================
    activity_distance_functions = []

    # Uncertain count-based family (12)
    activity_distance_functions.extend([
        "Uncertain AA Seq",
        "Uncertain AA Seq PMI",
        "Uncertain AA Seq PPMI",
        "Uncertain AA MSet",
        "Uncertain AA MSet PMI",
        "Uncertain AA MSet PPMI",
        "Uncertain AC Seq",
        "Uncertain AC Seq PMI",
        "Uncertain AC Seq PPMI",
        "Uncertain AC MSet",
        "Uncertain AC MSet PMI",
        "Uncertain AC MSet PPMI",
    ])

    # Uncertain act2vec
    activity_distance_functions.extend([
        "Uncertain act2vec CBOW",
        "Uncertain act2vec Skip-gram",
    ])

    # Mirror deterministic window-size evaluation convention (" ... w_3")
    window_size_list = [3, 5, 9]
    activity_distance_functions = add_window_size_evaluation(activity_distance_functions, window_size_list)

    # ==============================================================================
    # Parameters
    # ==============================================================================
    r_min = 10
    w = 5
    sampling_size = 5
    load_ground_truth_logs = False

    # ==============================================================================
    # Logs to evaluate (file names in uncertain_event_logs/)
    # ==============================================================================
    log_list = []
    log_list.append("ikea_asm__clip_based__c3d_and_p3d__p3d__pretrained__rgb__dev3__xes_uncertain_gt__no_na")
    # Add your real uncertain logs here (base name without extension).
    # Example:
    # log_list.append("xes_uncertain_gt__no_na")

    if not log_list:
        raise SystemExit(
            "Please edit `log_list` to include uncertain log base names found in `uncertain_event_logs/`."
        )

    evaluate_intrinsic_uncertain(
        activity_distance_functions,
        log_list,
        r_min,
        w,
        sampling_size,
        load_ground_truth_logs,
        na_label="NA",
    )


